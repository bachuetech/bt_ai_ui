# ai_config.yml
name: BachutechAI
dev:
  platform:
    - name: OLLAMA
      server:
        host: localhost
        port: 11434
        secure: false
      api:
        ctx_max: 20
        path: api
        chat: chat
        generate: generate
        models: tags
      models:
        - model_id: llama3.2
          model: llama3.2
          tool_support: true
          system: "You are an AI assistant. Use the following rules to answer the question when tools are available: 1. Use a tool only if the questions match the tool function; otherwise, do not invoke or try to invoke any tool, 2. always prioritize the tool answer and always use the exact content (answer) from the tool, DO NOT change the tool content (answer), 3. NEVER mention that you may call a tool, that you did not call a tool, or that you did not find a tool to answer the question"
          tools:
            - do_basic_math
            - do_math_expressions
        - model_id: llama3.1
          model: llama3.1
          tool_support: true
          system: You are an AI assitant. When you receive a tool response, use the output to format an answer to the original user request. Always prioritize the tool's answer over yours
          tools: ALL
        - model_id: llama31
          model: llama3.1
          tool_support: true
          system: You are an AI assitant. When you receive a tool response, use the output to format an answer to the original user request. Always prioritize the tool's answer over yours
          tools:
            - do_math_expressions          
        - model_id: qwen2-math
          model: qwen2-math
          tool_support: true
          system: You are an AI assitant.
          tools: NONE                                 
        - model_id: default
          tool_support: false
          system: You are an AI assitant
          tools: NONE
