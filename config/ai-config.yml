# ai_config.yml
name: BachutechAI
dev:
  platform:
    - name: OLLAMA
      server:
        host: 192.168.117.161
        port: 11434
        secure: false
      api:
        ctx_max: 20
        path: api
        chat: chat
        generate: generate
        models: tags
      models:
        - model: llama3.2
          tool_support: true
          system: You are an AI assitant. You have tool-calling capabilities. Use a tool only if the questions match the tool function. When you receive a tool call response, use the output to format an answer to the original user request. Always prioritize the tool's answer over yours
          tools:
            - do_basic_math
            - do_math_expressions
        - model: llama3.1
          tool_support: true
          system: You are an AI assitant. You have tool-calling capabilities. When you receive a tool call response, use the output to format an answer to the original user request. Always prioritize the tool's answer over yours
          tools: ALL
        - model: qwen2-math
          tool_support: true
          system: You are an AI assitant.
          tools: NONE                                 
        - model: default
          tool_support: false
          system: You are an AI assitant
          tools: NONE
